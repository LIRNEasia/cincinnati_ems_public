{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transport Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import operator\n",
    "import psycopg2\n",
    "import pylab\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from statsmodels.tsa import stattools\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import random\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.mlab as mlab\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "from statsmodels.graphics.api import qqplot\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "mpl.rcdefaults()\n",
    "pd.options.display.mpl_style = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read database parameters from default_profile\n",
    "dbitems = {}\n",
    "with open('default_profile') as f:\n",
    "    for line in f.readlines():\n",
    "        item = line.split(\" \")[1].split(\"=\")\n",
    "        dbitems[item[0]] = item[1].strip()\n",
    "        \n",
    "# Connect to database with psycopg2\n",
    "try:\n",
    "    conn = psycopg2.connect(\"dbname='%s' user='%s' host='%s' password='%s'\"%(dbitems['PGDATABASE'],dbitems['PGUSER'],dbitems['PGHOST'],dbitems['PGPASSWORD']))\n",
    "except:\n",
    "    print \"Unable to connect to the database\"\n",
    "    \n",
    "# Connect to database with sqalchemy\n",
    "conn_sqlalch = create_engine('postgresql+psycopg2://%s:%s@%s/%s'%(dbitems['PGUSER'],dbitems['PGPASSWORD'],dbitems['PGHOST'],dbitems['PGDATABASE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_NLN_format(s):\n",
    "    \"\"\"\n",
    "    input: string\n",
    "    output: True if s is in Number-Letter-Number format and False otherwise\n",
    "    \"\"\"\n",
    "    hit = re.match(r'\\d{1,2}[A-Z](\\d{1,2}|O)', s, flags = 0)\n",
    "    if hit:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get feature table\n",
    "feature_df = pd.read_sql_query(\"SELECT * from luigi_clean_cad.dbo_rfirehouseapparatus\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df = feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dictionary of codes\n",
    "master_dict = {\n",
    "    1:'ABDOMINAL PAIN',\n",
    "    2:'ALLERGIES',\n",
    "    3:'ANIMAL BITES',\n",
    "    4:'ASSAULT',\n",
    "    5:'BACK PAIN',\n",
    "    6:'BREATHING',\n",
    "    7:'BURNS',\n",
    "    8:'CARBON MONOXIDE',\n",
    "    9:'CARIAC/RESP ARREST',\n",
    "    10:'CHEST PAIN',\n",
    "    11:'CHOKING',\n",
    "    12:'CONVULSIONS/SEIZURES',\n",
    "    13:'DIABETIC PROBS',\n",
    "    14:'DROWNING',\n",
    "    15:'ELECTROCUTION',\n",
    "    16:'EYE PROBS',\n",
    "    17:'FALLS',\n",
    "    18:'HEADACHE',\n",
    "    19:'HEART PROBLEMS',\n",
    "    20:'HEAT/COLD EXPOSURE',\n",
    "    21:'HEMORRHAGE/LACERATIONS',\n",
    "    22:'ENTRAPMENT',\n",
    "    23:'OVERDOSE/POISONING',\n",
    "    24:'PREGNANCY',\n",
    "    25:'PHYCHIATRIC/SUICIDE ATTEMPT',\n",
    "    26:'SICK PERSON',\n",
    "    27:'STAB/GUNSHOT WOUND',\n",
    "    28:'STROKE',\n",
    "    29:'TRAFIC/TRANPORTATION INC',\n",
    "    30:'TRAUMATIC INJURIES',\n",
    "    31:'UNCONSCIOUS/FAINTING',\n",
    "    32:'UNKNOWN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get feature dataframe sum\n",
    "trns_df = feature_df.groupby(['i_eventnumber'])['trns_to_hosp'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find out of certain codes in NUM-LET-NUM format\n",
    "full_df['is_NLN'] = full_df['iti_typeid'].apply(is_NLN_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#groupby type\n",
    "gb_type = full_df.groupby('iti_typeid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get transport accuracy for each type of incident\n",
    "trns_acc = {}\n",
    "for name,group in gb_type:\n",
    "    trns_acc[name] = (group['trns_to_hosp']>0).sum()/float(len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prob_trns(typ, sev=''):\n",
    "    \"\"\"\n",
    "    Inputs typ which is numeric code of incident\n",
    "    and sev which is severity level: A,B,C,D,E...\n",
    "    \n",
    "    Return Double (x,y)\n",
    "    x = probability that incident requires tranport\n",
    "    y = probability that a given incident has the given type\n",
    "    \n",
    "    If no such incident, return error\n",
    "    \"\"\"\n",
    "    inc_type = typ+sev\n",
    "    try:\n",
    "        return trns_acc[inc_type]\n",
    "    except:\n",
    "        return 'Undefined Incident Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inc_df[0:100].to_sql('training', conn_sqlalch, if_exists = 'replace', schema = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('workfile', 'wr')\n",
    "f.write(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('workfile', 'r') as infile:\n",
    "    words = infile.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words[0] == 'complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first pass at logistic regression\n",
    "def gen_logistic_results(feature_df):\n",
    "    \"\"\"\n",
    "    input: dataframe of features for logistic regression\n",
    "    output: percent accuracy gain for each type of incident\n",
    "    \"\"\"\n",
    "\n",
    "    feature_df['hour'] = feature_df['i_ttimecreate'].apply(lambda x: x.hour)\n",
    "    feature_df = feature_df[feature_df['trns_to_hosp'].apply(lambda x: type(x) == bool)]\n",
    "\n",
    "    base = {}\n",
    "    scores = {}\n",
    "    thresh = 0.9\n",
    "    gb_type = feature_df.groupby('iti_typeid')\n",
    "    for name,group in gb_type:\n",
    "        if len(group) < thresh:\n",
    "            break\n",
    "\n",
    "        X = group['hour'][:, np.newaxis]\n",
    "        X_train = X[:int(thresh*len(X))]\n",
    "        X_test = X[int(thresh*len(X)):]\n",
    "\n",
    "        Y = [int(i) for i in group['trns_to_hosp']]\n",
    "        Y_train = Y[:int(thresh*len(Y))]\n",
    "        Y_test = Y[int(thresh*len(Y)):]\n",
    "\n",
    "        if len(set(Y_train)) > 1:\n",
    "            logreg = linear_model.LogisticRegression()\n",
    "            logreg.fit(X_train,Y_train)\n",
    "            pred = logreg.predict(X_test)\n",
    "            scores[name] = sum([int(i==j) for i,j in zip(pred, Y_test)])/float(len(Y_test))\n",
    "\n",
    "        prob = sum(Y)/float(len(Y))\n",
    "        base[name] = max(prob, 1-prob)\n",
    "            \n",
    "    results = pd.DataFrame(scores.items(), columns = ['inc_type_id', 'logistic_acc'])\n",
    "    \n",
    "    \n",
    "    base_list = []\n",
    "    for item in scores.keys():\n",
    "        base_list.append(base[item])\n",
    "    results['base_acc'] = base_list\n",
    "    results['pct_acc_gain'] = (results['logistic_acc'] - results['base_acc'])/results['base_acc']\n",
    "    return results\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
