{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import operator\n",
    "import psycopg2\n",
    "import pylab\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from statsmodels.tsa import stattools\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import random\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.mlab as mlab\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "from statsmodels.graphics.api import qqplot\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import metrics\n",
    "import time\n",
    "\n",
    "mpl.rcdefaults()\n",
    "pd.options.display.mpl_style = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read database parameters from default_profile\n",
    "dbitems = {}\n",
    "with open('default_profile') as f:\n",
    "    for line in f.readlines():\n",
    "        item = line.split(\" \")[1].split(\"=\")\n",
    "        dbitems[item[0]] = item[1].strip()\n",
    "        \n",
    "# Connect to database with psycopg2\n",
    "try:\n",
    "    conn = psycopg2.connect(\"dbname='%s' user='%s' host='%s' password='%s'\"%(dbitems['PGDATABASE'],dbitems['PGUSER'],dbitems['PGHOST'],dbitems['PGPASSWORD']))\n",
    "except:\n",
    "    print \"Unable to connect to the database\"\n",
    "    \n",
    "# Connect to database with sqalchemy\n",
    "conn_sqlalch = create_engine('postgresql+psycopg2://%s:%s@%s/%s'%(dbitems['PGUSER'],dbitems['PGPASSWORD'],dbitems['PGHOST'],dbitems['PGDATABASE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(s):\n",
    "    \"\"\"\n",
    "    input: string\n",
    "    output: replace space with dash and colon with dash and split on dashes\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.replace(' ', '-')\n",
    "    s = s.replace(':', '-')\n",
    "    l = s.split('-')\n",
    "    l = [int(i) for i in l]\n",
    "    return datetime.datetime(l[0], l[1], l[2], l[3], l[4], l[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cases(s):\n",
    "    \"\"\"\n",
    "    input: string\n",
    "    output: convert text incident types to their number counterparts\n",
    "    \"\"\"\n",
    "    if s == 'SUICF':\n",
    "        return '25'\n",
    "    elif s == 'DROWNF':\n",
    "        return '14'\n",
    "    elif s == 'ACCIF':\n",
    "        return '29'\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df = pickle.load( open( \"e69191e313e930617ef52e9d8549f0d2.p\", \"rb\" ))\n",
    "model = pickle.load(open(\"model_e69191e313e930617ef52e9d8549f0d2.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_df = pd.read_sql_query(\"SELECT * from features.master\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispatch_df = feature_df[['i_eventnumber', 'iti_typeid', 'iiu_tdispatch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispatch_df = dispatch_df.dropna()\n",
    "dispatch_df['code'] = dispatch_df['iti_typeid'].apply(lambda x: re.sub(r'[A-Z]+[0-9]+.*', '', x))\n",
    "dispatch_df['severity'] = dispatch_df.apply(lambda row: re.sub(r'[0-9]+', '', row.iti_typeid)[0] if row.code.isdigit() else 'NONE', axis = 1)\n",
    "dispatch_df['iiu_tdispatch'] = dispatch_df['iiu_tdispatch'].apply(get_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispatch_df = dispatch_df.sort('iiu_tdispatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispatch_df['time_day'] = dispatch_df['iiu_tdispatch'].apply(lambda x: datetime.datetime(x.year, x.month, x.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dispatch_df.index = dispatch_df.iiu_tdispatch\n",
    "dispatch_df = dispatch_df.drop('iiu_tdispatch' ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_type = dispatch_df.groupby('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for name,group in gb_type:\n",
    "    df_time = group.groupby('time_day').count()\n",
    "    df_time = df_time.sort_index()\n",
    "    df_time = pd.rolling_mean(df_time, window = 7).dropna()['i_eventnumber']\n",
    "    if len(df_time) > 0:\n",
    "        idx = pd.date_range(df_time.index[0], df_time.index[-1])\n",
    "        df_time.index = pd.DatetimeIndex(df_time.index)\n",
    "        df_time = df_time.reindex(idx, fill_value=0)\n",
    "        df_dict[name] = df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srs_key_1 = '29'\n",
    "srs_key_2 = '17'\n",
    "\n",
    "srs_1 = df_dict[srs_key_1]\n",
    "srs_2 = df_dict[srs_key_2]\n",
    "\n",
    "max_start = max(srs_1.index[0], srs_2.index[0])\n",
    "min_end = min(srs_1.index[-1], srs_2.index[-1])\n",
    "\n",
    "srs_1 = srs_1[(srs_1.index > max_start) & (srs_1.index < min_end)]\n",
    "srs_2 = srs_2[(srs_2.index > max_start) & (srs_2.index < min_end)]\n",
    "\n",
    "srs_1 = srs_1.values\n",
    "srs_2 = srs_2.values\n",
    "\n",
    "srs_pair = zip(srs_1, srs_2)\n",
    "\n",
    "item = statsmodels.tsa.stattools.grangercausalitytests(srs_pair, maxlag = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(df_dict['ACCIF'].index, df_dict['ACCIF'])\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df.index = result_df.incident\n",
    "feature_df.index = feature_df.incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df = result_df.join(feature_df, how = 'left', lsuffix = '_left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df['code_type'] = full_df['code_type'].apply(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df = full_df.drop('incident_left', 1)\n",
    "full_df = full_df.drop('incident', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    \"\"\"\n",
    "    input: real y's and y probabilities\n",
    "    output: a plot of precision and recall at k\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    \n",
    "    \n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metrics_at_k(y_true, y_scores, k):\n",
    "    \"\"\"\n",
    "    input: true y values and given scores from a model and a level at which to threshold\n",
    "    output: precision at k, recall at k, auc\n",
    "    \"\"\"\n",
    "    threshold = np.sort(y_scores)[::-1][int(k*len(y_scores))]\n",
    "    y_pred = [int(i >= threshold) for i in y_scores]\n",
    "    return (metrics.precision_score(y_true, y_pred), metrics.recall_score(y_true, y_pred), metrics.roc_auc_score(y_true, y_scores)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_dict = {\n",
    "    1:'ABDOM',\n",
    "    2:'ALLERGIES',\n",
    "    3:'ANIMAL BITES',\n",
    "    4:'ASSAULT',\n",
    "    5:'BACK',\n",
    "    6:'BREATH',\n",
    "    7:'BURNS',\n",
    "    8:'CARBON',\n",
    "    9:'CARDIAC',\n",
    "    10:'CHEST',\n",
    "    11:'CHOKE',\n",
    "    12:'CONVUL',\n",
    "    13:'DIAB',\n",
    "    14:'DROWN',\n",
    "    15:'ELECTRO',\n",
    "    16:'EYE',\n",
    "    17:'FALL',\n",
    "    18:'HEAD',\n",
    "    19:'HEART',\n",
    "    20:'HEAT',\n",
    "    21:'HEMORR',\n",
    "    22:'ENTRAP',\n",
    "    23:'OD',\n",
    "    24:'PREG',\n",
    "    25:'SUIC',\n",
    "    26:'SICK',\n",
    "    27:'STAB',\n",
    "    28:'STROKE',\n",
    "    29:'TRAFIC',\n",
    "    30:'TRAUMA',\n",
    "    31:'UNCONS',\n",
    "    32:'UNKNOWN'}\n",
    "\n",
    "sev_dict = {9: 2,19: 2, 28: 2, 10: 2, 27:2,  14:2, 12:1, 31:1, 13:1, 6:1,8:1, 23:1, 15:1, 7:1, 24:1, 25:1, 11:0, 2:0, 21:0, 3:0, 18:0, 16:0, 1:0, 20:0, 17:0, 26:0, 4:0, 29:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_urgency(s):\n",
    "    \"\"\"\n",
    "    input: string\n",
    "    output: severity level associated with incident coded by that string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return sev_dict[int(s)]\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df['urgency'] = full_df['code_type'].apply(get_urgency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_urg = full_df.groupby('time_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "for name,group in gb_urg:\n",
    "    print name, ' ', len(group)/float(len(full_df))\n",
    "    print \"actual pct pos:\", np.mean(group.trns_to_hosp)\n",
    "    print '-----'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_at_k(full_df.trns_to_hosp, full_df.new_y_probs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = [30,60,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_type = full_df.groupby('code_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_dict = {\n",
    "    1:'ABDOM',\n",
    "    2:'ALLERGIES',\n",
    "    3:'ANIMAL BITES',\n",
    "    4:'ASSAULT',\n",
    "    5:'BACK',\n",
    "    6:'BREATH',\n",
    "    7:'BURNS',\n",
    "    8:'CARBON',\n",
    "    9:'CARDIAC',\n",
    "    10:'CHEST',\n",
    "    11:'CHOKE',\n",
    "    12:'CONVUL',\n",
    "    13:'DIAB',\n",
    "    14:'DROWN',\n",
    "    15:'ELECTRO',\n",
    "    16:'EYE',\n",
    "    17:'FALL',\n",
    "    18:'HEAD',\n",
    "    19:'HEART',\n",
    "    20:'HEAT',\n",
    "    21:'HEMORR',\n",
    "    22:'ENTRAP',\n",
    "    23:'OD',\n",
    "    24:'PREG',\n",
    "    25:'SUIC',\n",
    "    26:'SICK',\n",
    "    27:'STAB',\n",
    "    28:'STROKE',\n",
    "    29:'TRAFIC',\n",
    "    30:'TRAUMA',\n",
    "    31:'UNCONS',\n",
    "    32:'UNKNOWN'}\n",
    "\n",
    "sev_dict = {9: 2,19: 2, 28: 2, 10: 2, 27:2,  14:2, 12:1, 31:1, 13:1, 6:1,8:1, 23:1, 15:1, 7:1, 24:1, 25:1, 11:0, 2:0, 21:0, 3:0, 18:0, 16:0, 1:0, 20:0, 17:0, 26:0, 4:0, 29:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_list = [9 ,19, 28, 10, 27,  14, 12, 31, 13, 6,8, 23, 15, 7, 24, 25, 11, 2, 21, 3, 18, 16, 1, 20, 17, 26, 4, 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_pct = {}\n",
    "dict_recall = {}\n",
    "dict_pop_prec = {}\n",
    "dict_pop_rec = {}\n",
    "for name,group in gb_type:\n",
    "    #problematic missing incident type\n",
    "    if name == '22':\n",
    "        continue\n",
    "    try:\n",
    "        z = int(name)\n",
    "        k_val = k[sev_dict[z]]\n",
    "        l =  group.y_pred_probs\n",
    "        cuttoff = np.percentile(l, 100-k_val)\n",
    "        group['predict'] = group.y_pred_probs.apply(lambda x: 1 if x > cuttoff else 0)\n",
    "        group['correct'] = group.apply(lambda x: int(x.trns_to_hosp == x.predict), axis = 1)\n",
    "        group['recalled'] = group.apply(lambda x: int(x.trns_to_hosp ==1 and  x.predict == 1), axis = 1)\n",
    "        x = int(name)\n",
    "        dict_pct[master_dict[x]] = (np.mean(group.correct) - np.mean(group.trns_to_hosp))/np.mean(group.trns_to_hosp)\n",
    "        dict_recall[master_dict[x]] = (sum(group.recalled) / float(sum(group.trns_to_hosp)) - k_val/100.0)/(k_val/100.0)\n",
    "        dict_pop_prec[master_dict[x]] = (np.mean(group.correct) - np.mean(group.trns_to_hosp))/np.mean(group.trns_to_hosp) * len(full_df[full_df['code_type'] == name])\n",
    "        dict_pop_rec[master_dict[x]] = (sum(group.recalled) / float(sum(group.trns_to_hosp)) - k_val/100.0)/(k_val/100.0) * len(full_df[full_df['code_type'] == name])\n",
    "    except ValueError:\n",
    "        continue\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_list = [9 ,19, 28, 10, 27,  14, 12, 31, 13, 6,8, 23, 15, 7, 24, 25, 11, 2, 21, 3, 18, 16, 1, 20, 17, 26, 4, 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_ord_list = [master_dict[i] for i in ord_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in name_ord_list:\n",
    "    tups.append((item, dict_pct[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tups_rec = []\n",
    "for item in name_ord_list:\n",
    "    tups_rec.append((item, dict_recall[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcdefaults()\n",
    "color_list = ['red']*6 + ['yellow'] * 11 + ['green'] * 12\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "ax.bar(range(1,len(tups)+1), [i[1] for i in tups], color = color_list, alpha = 0.9)\n",
    "ax.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax.set_ylabel('Precision Gain', fontsize = 16)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('actual_prec.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_prec = np.arange(0.1, 0.5, 0.4/len(tups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of Precision and Recall gain by incident type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcdefaults()\n",
    "color_list = ['red']*6 + ['yellow'] * 11 + ['green'] * 12\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "ax.bar(range(1,len(tups)+1), ideal_prec, color = color_list, alpha = 0.9)\n",
    "ax.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_ylabel('Precision Gain', fontsize = 16)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('good_prec.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcdefaults()\n",
    "color_list = ['red']*6 + ['yellow'] * 11 + ['green'] * 12\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "ax.bar(range(1,len(tups)+1), [i[1] for i in tups_rec], color = color_list, alpha = 0.9)\n",
    "ax.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax.set_ylabel('Recall Gain', fontsize = 16)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('actual_rec.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ideal_rec = np.arange(0.5, 0.1, -0.4/len(tups_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcdefaults()\n",
    "color_list = ['red']*6 + ['yellow'] * 11 + ['green'] * 12\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "ax.bar(range(1,len(tups)+1), ideal_rec, color = color_list, alpha = 0.9)\n",
    "ax.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax.set_ylabel('Recall Gain', fontsize = 16)\n",
    "ax.set_yticklabels([])\n",
    "plt.ylim(0,.52)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('good_rec.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = len(full_df[full_df['code_type'] == '27'])/float(len(full_df))\n",
    "y = len(full_df[full_df['code_type'] == '6'])/float(len(full_df))\n",
    "y / x\n",
    "# there are 300 times as many breathing as stabbings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tups_prec_pop = []\n",
    "for item in name_ord_list:\n",
    "    tups_prec_pop.append((item, dict_pop_prec[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tups_rec_pop = []\n",
    "for item in name_ord_list:\n",
    "    tups_rec_pop.append((item, dict_pop_rec[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcdefaults()\n",
    "color_list = ['red']*6 + ['yellow'] * 11 + ['green'] * 12\n",
    "f, (ax1, ax2) = plt.subplots(2,1,figsize=(12,8))\n",
    "\n",
    "ax1.bar(range(1,len(tups)+1), [i[1] for i in tups], color = color_list, alpha = 0.9)\n",
    "ax1.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax1.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax1.set_ylabel('Precision Gain', fontsize = 16)\n",
    "\n",
    "ax2.bar(range(1,len(tups)+1), [i[1] for i in tups_prec_pop], color = color_list, alpha = 0.9)\n",
    "ax2.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax2.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax2.set_ylabel('Scaled Precision Gain', fontsize = 16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig('scaled_prec.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tups_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcdefaults()\n",
    "color_list = ['red']*6 + ['yellow'] * 11 + ['green'] * 12\n",
    "f, (ax1, ax2) = plt.subplots(2,1,figsize=(12,8))\n",
    "\n",
    "ax1.bar(range(1,len(tups_rec)+1), [i[1] for i in tups_rec], color = color_list, alpha = 0.9)\n",
    "ax1.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax1.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax1.set_ylabel('Recall Gain', fontsize = 16)\n",
    "\n",
    "ax2.bar(range(1,len(tups_rec_pop)+1), [i[1] for i in tups_rec_pop], color = color_list, alpha = 0.9)\n",
    "ax2.set_xticks(np.arange(1.45,len(tups)+1.45, 1))\n",
    "ax2.set_xticklabels([i[0] for i in tups], rotation = 90)\n",
    "ax2.set_ylabel('Scaled Recall Gain', fontsize = 16)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('scaled_rec.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp = model.feature_importances_\n",
    "feats = [u'common_weather_awnd', u'common_weather_dapr', u'common_weather_fmtm', u'common_weather_mdpr', u'common_weather_pgtm', u'common_weather_prcp', u'common_weather_snow', u'common_weather_snwd', u'common_weather_tmax', u'common_weather_tmin', u'common_weather_tobs', u'common_weather_wdf2', u'common_weather_wdf5', u'common_weather_wesd', u'common_weather_wesf', u'common_weather_wsf2', u'common_weather_wsf5', u'time_of_day_is_1p-7p', u'time_of_day_is_7a-1p', u'time_of_day_is_7p-1a', u'time_year_is_2012.0', u'time_year_is_2013.0', u'time_year_is_2014.0', u'time_year_is_2015.0', u'time_year_is_2016.0', u'time_month_is_2.0', u'time_month_is_3.0', u'time_month_is_4.0', u'time_month_is_5.0', u'time_month_is_6.0', u'time_month_is_7.0', u'time_month_is_8.0', u'time_month_is_9.0', u'time_month_is_10.0', u'time_month_is_11.0', u'time_month_is_12.0', u'time_day_is_2.0', u'time_day_is_3.0', u'time_day_is_4.0', u'time_day_is_5.0', u'time_day_is_6.0', u'time_day_is_7.0', u'time_day_is_8.0', u'time_day_is_9.0', u'time_day_is_10.0', u'time_day_is_11.0', u'time_day_is_12.0', u'time_day_is_13.0', u'time_day_is_14.0', u'time_day_is_15.0', u'time_day_is_16.0', u'time_day_is_17.0', u'time_day_is_18.0', u'time_day_is_19.0', u'time_day_is_20.0', u'time_day_is_21.0', u'time_day_is_22.0', u'time_day_is_23.0', u'time_day_is_24.0', u'time_day_is_25.0', u'time_day_is_26.0', u'time_day_is_27.0', u'time_day_is_28.0', u'time_day_is_29.0', u'time_day_is_30.0', u'time_day_is_31.0', u'time_hour_is_1.0', u'time_hour_is_2.0', u'time_hour_is_3.0', u'time_hour_is_4.0', u'time_hour_is_5.0', u'time_hour_is_6.0', u'time_hour_is_7.0', u'time_hour_is_8.0', u'time_hour_is_9.0', u'time_hour_is_10.0', u'time_hour_is_11.0', u'time_hour_is_12.0', u'time_hour_is_13.0', u'time_hour_is_14.0', u'time_hour_is_15.0', u'time_hour_is_16.0', u'time_hour_is_17.0', u'time_hour_is_18.0', u'time_hour_is_19.0', u'time_hour_is_20.0', u'time_hour_is_21.0', u'time_hour_is_22.0', u'time_hour_is_23.0', u'code_type_is_10', u'code_type_is_11', u'code_type_is_12', u'code_type_is_13', u'code_type_is_14', u'code_type_is_15', u'code_type_is_16', u'code_type_is_17', u'code_type_is_18', u'code_type_is_19', u'code_type_is_2', u'code_type_is_20', u'code_type_is_21', u'code_type_is_22', u'code_type_is_23', u'code_type_is_24', u'code_type_is_25', u'code_type_is_26', u'code_type_is_27', u'code_type_is_28', u'code_type_is_29', u'code_type_is_3', u'code_type_is_30', u'code_type_is_31', u'code_type_is_32', u'code_type_is_4', u'code_type_is_5', u'code_type_is_6', u'code_type_is_7', u'code_type_is_8', u'code_type_is_9', u'code_type_is_ACCIF', u'code_type_is_AIRF', u'code_type_is_ASSLTF', u'code_type_is_BIOHZF', u'code_type_is_BLDGF', u'code_type_is_BOATF', u'code_type_is_BOMB', u'code_type_is_CALARM', u'code_type_is_CHEMF', u'code_type_is_CHEMI', u'code_type_is_COLAPS', u'code_type_is_COSICK', u'code_type_is_CUTF', u'code_type_is_DETAIL', u'code_type_is_DOMINF', u'code_type_is_DOMNF', u'code_type_is_DROWNF', u'code_type_is_EMS', u'code_type_is_FADV', u'code_type_is_FALARM', u'code_type_is_FDRILL', u'code_type_is_FHELPF', u'code_type_is_FRO', u'code_type_is_FSERV', u'code_type_is_FTEST', u'code_type_is_FTRACC', u'code_type_is_FUMES', u'code_type_is_GAS1', u'code_type_is_GAS2', u'code_type_is_HEROIF', u'code_type_is_HERONF', u'code_type_is_HIRISK', u'code_type_is_HYDR', u'code_type_is_INACTF', u'code_type_is_INFOF', u'code_type_is_INVEST', u'code_type_is_LOCK', u'code_type_is_MENTIF', u'code_type_is_MUTUAL', u'code_type_is_OUTDR', u'code_type_is_OUTLET', u'code_type_is_PDOAF', u'code_type_is_PERDWF', u'code_type_is_PHELPF', u'code_type_is_POSTAF', u'code_type_is_RAPEF', u'code_type_is_RIVERF', u'code_type_is_ROBBIF', u'code_type_is_SALV', u'code_type_is_SHOOTF', u'code_type_is_SIG500', u'code_type_is_STRUCT', u'code_type_is_STUCK', u'code_type_is_SUICF', u'code_type_is_SWAT', u'code_type_is_TASER', u'code_type_is_TESTC', u'code_type_is_TESTF', u'code_type_is_TRAP', u'code_type_is_TRAPF', u'code_type_is_TRK', u'code_type_is_VEH', u'code_type_is_WALKIN', u'code_type_is_WATERR', u'code_type_is_WIRES', u'code_level_is_B', u'code_level_is_C', u'code_level_is_CO', u'code_level_is_D', u'code_level_is_E', u'code_level_is_O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_imp = dict(zip(feats, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "code_feat_sum = sum([d_imp[i] for i in feats if 'code_' in i])\n",
    "com_weather_feat_sum = sum([d_imp[i] for i in feats if 'common_' in i])\n",
    "ext_weather_feat_sum = sum([d_imp[i] for i in feats if 'extreme_' in i])\n",
    "code_type_sum = sum([d_imp[i] for i in feats if 'code_type' in i])\n",
    "code_level_sum = sum([d_imp[i] for i in feats if 'code_level' in i])\n",
    "\n",
    "code_imp = [d_imp[i] for i in feats if 'code_type' in i]\n",
    "code_sev = [d_imp[i] for i in feats if 'code_level' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_code = {}\n",
    "for key,value in d_imp.iteritems():\n",
    "    if 'code_type' in key:\n",
    "        dict_code[key] = d_imp[key]/sum(code_imp)\n",
    "dict_code_level = {}\n",
    "for key,value in d_imp.iteritems():\n",
    "    if 'code_level' in key:\n",
    "        dict_code_level[key] = d_imp[key]/sum(code_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_x = sorted(dict_code.items(), key=operator.itemgetter(1))\n",
    "sorted_x_lev = sorted(dict_code_level.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_x = sorted_x[::-1]\n",
    "sorted_x_lev = sorted_x_lev[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_x = sorted_x[:5]\n",
    "sorted_x_lev = sorted_x_lev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = [i[1] for i in sorted_x]\n",
    "vals_lev = [i[1] for i in sorted_x_lev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals.append(1-sum(vals))\n",
    "vals_lev.append(1-sum(vals_lev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 9.0\n",
    "\n",
    "pct_sizes = [14,0,0]\n",
    "name_sizes = [0,0,0]\n",
    "\n",
    "pct_sizes_2 = [10,10,10,10,10,0]\n",
    "name_sizes_2 = [10,10,10,10,10,10]\n",
    "\n",
    "\n",
    "\n",
    "labels = ['CODE', 'WEATHER', 'TIME']\n",
    "labs_2 = ['FADV', 'FIRE ALARM', 'BREATH', 'CHEST', 'INFOF', 'OTHER']\n",
    "\n",
    "sizes = [code_feat_sum, com_weather_feat_sum, 1-code_feat_sum-com_weather_feat_sum]\n",
    "colors = ['cornflowerblue', 'gold','mediumseagreen']\n",
    "colors_2 = ['indianred', 'violet', 'orangered', 'palegreen', 'darksalmon', 'darkgrey']\n",
    "\n",
    "patches, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors = colors,pctdistance=.85, labeldistance=1.05)\n",
    "for item in texts:\n",
    "    item.set_fontsize(14)\n",
    "for i in range(len(pct_sizes)):\n",
    "    autotexts[i].set_fontsize(pct_sizes[i])\n",
    "for i in range(len(name_sizes)):\n",
    "    texts[i].set_fontsize(name_sizes[i])\n",
    "\n",
    "#centre_circle = plt.Circle((0,0),0.7,color='black', fc='white',linewidth=1.25)\n",
    "#fig = plt.gcf()\n",
    "#fig.gca().add_artist(centre_circle)\n",
    "\n",
    "\n",
    "\n",
    "centre_circle = plt.Circle((0,0),0.6,color='black', fc='white',linewidth=1.25)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.text(.03,.9,'TIME', fontsize = 14 , rotation = 85)\n",
    "plt.text(.11,.9,'WEATHER', fontsize = 14 , rotation = 77)\n",
    "plt.text(.4,-.75,'CODE', fontsize = 14)\n",
    "\n",
    "\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pie_feat.pdf')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 9.0\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "pct_sizes = [14,0,0]\n",
    "name_sizes = [0,0,0]\n",
    "\n",
    "pct_sizes_2 = [10,10,10,10,10,0]\n",
    "name_sizes_2 = [10,10,10,10,10,10]\n",
    "\n",
    "\n",
    "\n",
    "labels = ['CODE', 'WEATHER', 'TIME']\n",
    "labs_2 = ['FADV', 'FIRE ALARM', 'BREATH', 'CHEST', 'INFOF', 'OTHER']\n",
    "\n",
    "sizes = [code_feat_sum, com_weather_feat_sum, 1-code_feat_sum-com_weather_feat_sum]\n",
    "colors = ['cornflowerblue', 'gold','mediumseagreen']\n",
    "colors_2 = ['indianred', 'violet', 'orangered', 'hotpink', 'darksalmon', 'darkgrey']\n",
    "\n",
    "patches, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors = colors,pctdistance=.85, labeldistance=1.05)\n",
    "for item in texts:\n",
    "    item.set_fontsize(14)\n",
    "for i in range(len(pct_sizes)):\n",
    "    autotexts[i].set_fontsize(pct_sizes[i])\n",
    "for i in range(len(name_sizes)):\n",
    "    texts[i].set_fontsize(name_sizes[i])\n",
    "\n",
    "#centre_circle = plt.Circle((0,0),0.7,color='black', fc='white',linewidth=1.25)\n",
    "#fig = plt.gcf()\n",
    "#fig.gca().add_artist(centre_circle)\n",
    "\n",
    "patches2, texts2, autotexts2 = plt.pie(vals, labels=labs_2, autopct='%1.1f%%', startangle=90, colors = colors_2,pctdistance=.85, labeldistance=1.05, radius = 0.6)\n",
    "fig = plt.gcf()\n",
    "for item in texts2:\n",
    "    item.set_fontsize(14)\n",
    "for i in range(len(pct_sizes_2)):\n",
    "    autotexts2[i].set_fontsize(pct_sizes_2[i])\n",
    "for i in range(len(name_sizes_2)):\n",
    "    texts2[i].set_fontsize(name_sizes_2[i])\n",
    "#fig.gca().add_artist(centre_circle)\n",
    "\n",
    "centre_circle = plt.Circle((0,0),0.4,color='black', fc='white',linewidth=1.25)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "#ax.annotate('CODE TYPE', xy=(2,1), xytext=(1,2))\n",
    "plt.text(.03,.9,'TIME', fontsize = 14 , rotation = 85)\n",
    "plt.text(.11,.9,'WEATHER', fontsize = 14 , rotation = 77)\n",
    "plt.text(.4,-.75,'CODE', fontsize = 14)\n",
    "\n",
    "plt.text(-.20,0,'CODE TYPE', fontsize = 14)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pie_loc.pdf')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 9.0\n",
    "\n",
    "pct_sizes = [14,0,0]\n",
    "name_sizes = [0,0,0]\n",
    "\n",
    "pct_sizes_2 = [10,10,10,10,10,0]\n",
    "name_sizes_2 = [10,10,10,10,10,10]\n",
    "\n",
    "pct_sizes_3 = [11,11,0]\n",
    "name_sizes_3 = [14,14,0]\n",
    "\n",
    "\n",
    "\n",
    "labels = ['CODE', 'WEATHER', 'TIME']\n",
    "#labs_2 = ['FADV', 'FIRE ALARM', 'BREATH', 'CHEST', 'INFOF', 'OTHER']\n",
    "labs_3 = ['D', 'C','OTHER']\n",
    "\n",
    "sizes = [code_feat_sum, com_weather_feat_sum, 1-code_feat_sum-com_weather_feat_sum]\n",
    "colors = ['cornflowerblue', 'gold','mediumseagreen']\n",
    "colors_2 = ['indianred', 'violet', 'darkgrey']\n",
    "\n",
    "\n",
    "\n",
    "patches, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors = colors,pctdistance=.85, labeldistance=1.05)\n",
    "for item in texts:\n",
    "    item.set_fontsize(14)\n",
    "for i in range(len(pct_sizes)):\n",
    "    autotexts[i].set_fontsize(pct_sizes[i])\n",
    "for i in range(len(name_sizes)):\n",
    "    texts[i].set_fontsize(name_sizes[i])\n",
    "\n",
    "#centre_circle = plt.Circle((0,0),0.7,color='black', fc='white',linewidth=1.25)\n",
    "#fig = plt.gcf()\n",
    "#fig.gca().add_artist(centre_circle)\n",
    "\n",
    "patches2, texts2, autotexts2 = plt.pie(vals_lev, labels=labs_3, autopct='%1.1f%%', startangle=90, colors = colors_2,pctdistance=.85, labeldistance=1.05, radius = 0.6)\n",
    "fig = plt.gcf()\n",
    "for item in texts2:\n",
    "    item.set_fontsize(14)\n",
    "for i in range(len(pct_sizes_3)):\n",
    "    autotexts2[i].set_fontsize(pct_sizes_3[i])\n",
    "for i in range(len(name_sizes_3)):\n",
    "    texts2[i].set_fontsize(name_sizes_3[i])\n",
    "#fig.gca().add_artist(centre_circle)\n",
    "\n",
    "centre_circle = plt.Circle((0,0),0.4,color='black', fc='white',linewidth=1.25)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.text(.03,.9,'TIME', fontsize = 14 , rotation = 85)\n",
    "plt.text(.11,.9,'WEATHER', fontsize = 14 , rotation = 77)\n",
    "plt.text(.4,-.75,'CODE', fontsize = 14)\n",
    "\n",
    "plt.text(-.27,0,'CODE SEVERITY', fontsize = 14)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('pie_sev.pdf')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = ['common_weather_prcp', 'common_weather_wesf', 'common_weather_wsf2', 'common_weather_awnd', 'common_weather_pgtm', 'common_weather_tmin', 'common_weather_wdf5', 'common_weather_mdpr', 'common_weather_wesd', 'common_weather_fmtm', 'common_weather_wdf2', 'common_weather_snow', 'common_weather_tmax', 'common_weather_dapr', 'common_weather_snwd', 'common_weather_wsf5', 'common_weather_tobs', 'time_of_day_is_7p-1a', 'time_month_is_10.0', 'time_day_is_27.0', 'time_day_is_11.0', 'time_day_is_15.0', 'time_year_is_2016.0', 'time_year_is_2014.0', 'time_of_day_is_7a-1p', 'time_day_is_4.0', 'time_month_is_2.0', 'time_month_is_3.0', 'time_month_is_9.0', 'time_day_is_22.0', 'time_day_is_19.0', 'time_day_is_14.0', 'time_day_is_26.0', 'time_day_is_25.0', 'time_day_is_9.0', 'time_month_is_11.0', 'time_day_is_20.0', 'time_day_is_29.0', 'time_month_is_6.0', 'time_year_is_2012.0', 'time_day_is_10.0', 'time_month_is_8.0', 'time_day_is_2.0', 'time_year_is_2015.0', 'time_month_is_4.0', 'time_day_is_24.0', 'time_day_is_5.0', 'time_of_day_is_1p-7p', 'time_year_is_2013.0', 'time_month_is_7.0', 'time_month_is_12.0', 'time_day_is_23.0', 'time_day_is_18.0', 'time_day_is_31.0', 'time_day_is_13.0', 'time_day_is_8.0', 'time_day_is_12.0', 'time_day_is_7.0', 'time_day_is_21.0', 'time_day_is_17.0', 'time_day_is_30.0', 'time_day_is_6.0', 'time_day_is_28.0', 'time_month_is_5.0', 'time_day_is_3.0', 'time_day_is_16.0', 'code_type_is_GAS2', 'code_type_is_6', 'code_type_is_HEROIF', 'code_type_is_DROWNF', 'code_type_is_MUTUAL', 'code_type_is_COLAPS', 'code_type_is_BOATF', 'code_type_is_COSICK', 'code_type_is_23', 'code_type_is_FHELPF', 'code_type_is_EMS', 'code_level_is_C', 'code_type_is_12', 'code_type_is_PHELPF', 'code_type_is_GAS1', 'code_type_is_DOMNF', 'code_type_is_CHEMI', 'code_type_is_TESTC', 'code_type_is_24', 'code_type_is_TASER', 'code_type_is_FADV', 'code_type_is_32', 'code_level_is_D', 'code_type_is_15', 'code_type_is_ASSLTF', 'code_type_is_4', 'code_type_is_SUICF', 'code_type_is_OUTDR', 'code_type_is_HERONF', 'code_type_is_25', 'code_type_is_WALKIN', 'code_type_is_ACCIF', 'code_type_is_FRO', 'code_type_is_STUCK', 'code_type_is_POSTAF', 'code_type_is_14', 'code_type_is_31', 'code_type_is_CUTF', 'code_type_is_PDOAF', 'code_level_is_O', 'code_type_is_5', 'code_type_is_AIRF', 'code_type_is_SHOOTF', 'code_type_is_TRAP', 'code_type_is_17', 'code_type_is_30', 'code_type_is_26', 'code_type_is_CALARM', 'code_type_is_INACTF', 'code_type_is_TESTF', 'code_type_is_28', 'code_type_is_VEH', 'code_type_is_2', 'code_type_is_INFOF', 'code_type_is_WIRES', 'code_type_is_SIG500', 'code_type_is_16', 'code_type_is_DETAIL', 'code_type_is_27', 'code_type_is_29', 'code_level_is_CO', 'code_type_is_TRK', 'code_type_is_BIOHZF', 'code_type_is_3', 'code_type_is_MENTIF', 'code_type_is_FUMES', 'code_type_is_HYDR', 'code_type_is_RIVERF', 'code_type_is_WATERR', 'code_type_is_INVEST', 'code_type_is_19', 'code_type_is_CHEMF', 'code_type_is_11', 'code_type_is_20', 'code_type_is_BOMB', 'code_type_is_ROBBIF', 'code_type_is_HIRISK', 'code_type_is_FTEST', 'code_type_is_RAPEF', 'code_type_is_FALARM', 'code_type_is_DOMINF', 'code_type_is_7', 'code_type_is_OUTLET', 'code_type_is_8', 'code_type_is_18', 'code_type_is_10', 'code_type_is_STRUCT', 'code_type_is_TRAPF', 'code_type_is_21', 'code_level_is_E', 'code_type_is_FDRILL', 'code_type_is_LOCK', 'code_type_is_BLDGF', 'code_type_is_PERDWF', 'code_type_is_SALV', 'code_level_is_B', 'code_type_is_9', 'code_type_is_SWAT', 'code_type_is_FTRACC', 'code_type_is_13', 'code_type_is_FSERV', 'code_type_is_22', 'weather_event_mist', 'weather_event_glaze', 'weather_event_rain', 'weather_event_unknown_precip', 'weather_event_freezing_drizzle', 'weather_event_ground_fog', 'weather_event_drizzle', 'weather_event_thunder', 'weather_event_ice_fog', 'weather_event_heavy_fog', 'weather_event_smoke', 'weather_event_snow', 'weather_event_freezing_rain', 'weather_event_hail', 'weather_event_high_winds', 'station_name_is_ST03', 'station_name_is_ST34', 'station_name_is_ST31', 'station_name_is_ST51', 'station_name_is_ST35', 'station_name_is_ST21', 'station_name_is_ST50', 'station_name_is_ST18', 'station_name_is_ST46', 'station_name_is_ST32', 'station_name_is_ST05', 'station_name_is_ST20', 'station_name_is_ST23', 'station_name_is_ST07', 'station_name_is_ST19', 'station_name_is_ST29', 'station_name_is_ST17', 'station_name_is_ST12', 'station_name_is_ST02B', 'station_name_is_ST38', 'station_name_is_ST14', 'station_name_is_ST09', 'station_name_is_ST24', 'station_name_is_ST49', 'station_name_is_ST08', 'station_name_is_ST37', 'within_1day_full_moon', 'acs_edu', 'acs_no_insurance', 'acs_white', 'acs_income', 'acs_black', 'acs_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "model1 = pickle.load(open('model_e69191e313e930617ef52e9d8549f0d2.p', 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_imp = dict(zip(feats, model1.coef_[0]))\n",
    "imps = zip(feats, model1.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(imps, key = lambda x:abs(x[1]))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code_feat_sum = sum([abs(d_imp[i]) for i in feats if 'code_' in i])\n",
    "com_weather_feat_sum = sum([abs(d_imp[i]) for i in feats if 'common_' in i])\n",
    "ext_weather_feat_sum = sum([abs(d_imp[i]) for i in feats if 'weather_event_' in i])\n",
    "acs_sum = sum([abs(d_imp[i]) for i in feats if 'acs_' in i])\n",
    "station_sum = sum([abs(d_imp[i]) for i in feats if 'station_' in i])\n",
    "time_sum = sum([abs(d_imp[i]) for i in feats if 'time_' in i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = float(code_feat_sum + com_weather_feat_sum + ext_weather_feat_sum + acs_sum + station_sum + time_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print code_feat_sum / total\n",
    "print com_weather_feat_sum / total\n",
    "print ext_weather_feat_sum / total\n",
    "print acs_sum / total\n",
    "print station_sum / total\n",
    "print time_sum / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code_feat_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = full_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.isnull(full_df.score).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_at_k(full_df.trns_to_hosp, full_df.score, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "l = precision_recall_curve(full_df.trns_to_hosp, full_df.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(l[2], l[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = '-high: 3 -5 -1 1 \\n -med: 3 -5 -1 1 \\n -low: 3 -5 -1 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = s.replace(' ', '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_tups = []\n",
    "weight_str = re.findall(r'-.*[0-9].*[0-9].*[0-9].*[0-9]', self.weights)\n",
    "for item in weight_str:\n",
    "    l = (item.strip('-').split(':'))\n",
    "    weights = [float(i) for i in l[1].split('|')[1:]]\n",
    "    weight_tups.append((l[0], weights))\n",
    "\n",
    "weight_dict = {}\n",
    "for item in weight_tups:\n",
    "    weight_dict[item[0]] = item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tups = [(1,1), (1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum([i[0] == i[1] for i in tups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for code in set(full_df['code_type']):\n",
    "    try:\n",
    "        type_df = full_df[full_df['code_type'] == code]\n",
    "\n",
    "        curr_df = type_df[['m_required', 'trns_to_hosp']]\n",
    "\n",
    "        curr_df = curr_df.dropna()\n",
    "\n",
    "        def type_of_pred(pred, obs):\n",
    "            \"\"\"\n",
    "            input: prediction and observation\n",
    "            output: whether this is a True Positive, False Pos, False Neg, or True Neg\n",
    "            \"\"\"\n",
    "            if pred and obs:\n",
    "                return 'TP'\n",
    "            elif pred and not obs:\n",
    "                return 'FP'\n",
    "            elif not pred and obs:\n",
    "                return 'FN'\n",
    "            else:\n",
    "                return 'TN'\n",
    "        curr_df['class'] = curr_df.apply(lambda x: type_of_pred(x.m_required, x.trns_to_hosp), axis =1)\n",
    "\n",
    "        new_df = type_df[['score', 'trns_to_hosp']]\n",
    "\n",
    "        new_df = new_df.dropna()\n",
    "\n",
    "        v = np.percentile(new_df['score'], 100-44.5)\n",
    "\n",
    "        new_df['pred'] = new_df['score'].apply(lambda x: True if x >= v else False)\n",
    "\n",
    "        new_df['class'] = new_df.apply(lambda x: type_of_pred(x.pred, x.trns_to_hosp), axis =1)\n",
    "\n",
    "        gb_class_old = curr_df.groupby('class')\n",
    "        gb_class_new = new_df.groupby('class')\n",
    "\n",
    "\n",
    "        \"\"\"for name,group in gb_class_old:\n",
    "            print name, len(group)/float(len(curr_df))\n",
    "        print '---------'\n",
    "        for name,group in gb_class_new:\n",
    "            print name, len(group)/float(len(new_df))\"\"\"\n",
    "\n",
    "        if len([i for i in curr_df['class'] if i == 'TP']) + len([i for i in curr_df['class'] if i == 'FN']) == 0:\n",
    "            print code\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df[['trns_to_hosp', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = new_df[['trns_to_hosp', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.reindex(np.random.permutation(t.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = open('e69191e313e930617ef52e9d8549f0d2.jsonb' ,'rw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print model1.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = feature_df[['trns_to_hosp', 'm_required', 'code_type', 'time_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_val= 0\n",
    "for code in set(x.code_type):\n",
    "    new = len(x[(x['trns_to_hosp'] == False)&(x['m_required'] == True)&(x['code_type'] == code)&(x['time_year'] <= 2015)&(x['time_year'] >= 2013)])\n",
    "    if new > max_val:\n",
    "        max_val = new\n",
    "        print code, new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(feature_df.time_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
